# -*- coding: utf-8 -*-
"""plot_statvar_time_series.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rgAt2PkML8a4n4L1I-FzaMBtEiBo8qnj
"""

from google.colab import auth
auth.authenticate_user()
print('Authenticated')

from google.cloud import bigquery
project_id = "google.com:datcom-store-dev"
client = bigquery.Client(project=project_id)

obs_cols = [
    'id', 'prov_id', 'is_public', 'observed_node_key', 'start_time_us',
    'end_time_us', 'duration', 'measured_prop', 'sum_value', 'min_value',
    'max_value', 'mean_value', 'median_value', 'measured_value', 'p10',
    'p25', 'p75', 'p90', 'unit', 'sample_size', 'margin_of_error',
    'std_error', 'mean_std_error', 'measurement_method', 'observation_date',
    'observation_period', 'measurement_result', 'growth_rate', 'fake_date',
    'compared_node_key', 'type', 'comparison_operator',
    'std_deviation_value', 'location_key', 'measurement_denominator',
    'scaling_factor', 'measurement_qualifier'
]

# Specify the DCID of your StatisticalVariable
statvar_id = "US_PPI_Meats"

# Define your axes
x = "observation_date"
y = "measured_value"
sort_x = True
group = ""

triples_query = f'SELECT * FROM `google.com:datcom-store-dev.dc_v3_dev.Triple` WHERE subject_id = "{statvar_id}"'
triples = client.query(triples_query).to_dataframe().drop_duplicates(subset=["predicate"])
triples

ignore = set(["localCuratorLevelId", "name", "statType", "typeOf", "populationType"])
col_mappings = {
    "measuredProperty": "measured_prop", "measurementMethod": "measurement_method",
    "measurementQualifier": "measurement_qualifier", "unit": "unit"
}
pop = triples[triples.predicate == "populationType"].object_id.values[0]

# Narrow down the series
conjunction_dict = {}
values = set()
for _, row in triples.iterrows():
    prop = row["predicate"]
    if prop in ignore:
        continue
    if prop not in col_mappings:
        values.add(row["object_id"])
        continue
    conjunction_dict[col_mappings[prop]] = row["object_id"]

print(conjunction_dict)
print(values)

pop_query = f'SELECT * FROM `google.com:datcom-store-dev.dc_v3_dev.StatisticalPopulation` WHERE population_type = "{pop}"'
print(pop_query)

pops = client.query(pop_query).to_dataframe()
pops

pop_id = None
values_to_test = set()
for _, row in pops.iterrows():
    if not values:
        found = True
        for i in range(1, 11):
            if row[f"p{i}"]:
                found = False
        if found:
            pop_id = row["id"]
            break
    
    values_to_test.clear()
    for i in range(1, 11):
        if row[f"p{i}"]:
            values_to_test.add(row[f"v{i}"])
    if values == values_to_test:
        pop_id = row["id"]
        break

if pop_id:
    conjunction_dict["observed_node_key"] = pop_id
    print(pop_id)

where = ""
for i, col_val in enumerate(conjunction_dict.items()):
    col, val = col_val
    if not where:
        where = "WHERE "
    where += col + " = " + f'"{val}" '
    if i != len(conjunction_dict) - 1:
        where += "AND "
print(where)

query = 'SELECT * FROM `google.com:datcom-store-dev.dc_v3_dev.Observation` ' + where
print(query)

obs = client.query(query).to_dataframe()
if sort_x:
    obs.sort_values(by=x, inplace=True)
obs.head()

if group:
    obs.groupby(by=group).plot(x=x, y=y, figsize=(20, 10))
else:    
    obs.plot(x=x, y=y, figsize=(20, 10))