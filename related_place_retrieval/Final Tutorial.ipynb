{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome!\n",
    "Welcome to this Colab notebook! We will walk you through several examples of exploring similar and dissimilar counties in US based on statistical variable values in Data Commons datasets. There are primarily two types of data we define here:\n",
    "1. Snapshot. We look at the statistical variable value at a given time (most likely the latest observation). The similarity criterion we used is absolute difference between two values.\n",
    "2. Time series. We look at all available statistical variable values as a time series. The similarity criterion can be either Pearson correlation (pearson), or Mean Square Error (mse).\n",
    "\n",
    "We hope the examples can help you better understand Data Commons and how to use it, so that further research / analysis can be conducted easily"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from scipy.stats import rankdata, pearsonr\n",
    "import datacommons as dc\n",
    "import numpy as np\n",
    "import copy\n",
    "import pandas as pd\n",
    "from urllib.request import urlopen\n",
    "import json\n",
    "import plotly.express as px\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Argument Parsing\n",
    "1. query_dcid: this is the county we are looking at.\n",
    "2. restrict_same_state: True if we want to only compare query county with counties in the same state.\n",
    "3. K: number of similar/dissimilar counties to retrieve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_dcid = 'geoId/06085' # Santa Clara county\n",
    "# query_dcid = 'geoId/15001' # Hawaii county\n",
    "restrict_same_state = True # only retrieving and ranking places that are in the same state\n",
    "K = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all the state and county information we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if restrict_same_state:\n",
    "    place_domain = dc.get_property_values([query_dcid], 'containedInPlace')[query_dcid][0]\n",
    "else:\n",
    "    place_domain = 'country/USA'\n",
    "all_states = dc.get_places_in(['country/USA'], \"State\")['country/USA']\n",
    "all_states = dc.get_property_values(all_states, \"name\")\n",
    "all_counties = dc.get_places_in([place_domain], \"County\")[place_domain]\n",
    "all_counties = dc.get_property_values(all_counties, \"name\")\n",
    "id_list = sorted(list(all_counties.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single statistical variable snapshot case\n",
    "First, let's look at one statistical variable say unemployment rate for snapshot case. For this statistical variable, it does not make sense to look at it on a per capita basis, so we set it to False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statvars = ['UnemploymentRate_Person']\n",
    "per_capita = [False]\n",
    "time_series = [False]\n",
    "time_series_similarity_types = ['pearson']  # either pearson or mse for time series similarity metric\n",
    "statvar_display_names = ['Unemployment Rate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all the raw data we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_and_population(all_counties, statvars):\n",
    "    data = []\n",
    "    for i in range(len(statvars)):\n",
    "        data.append(dc.get_stats(all_counties, statvars[i], obs_dates=\"all\"))\n",
    "    population = dc.get_stats(all_counties, 'Count_Person', obs_dates='all')\n",
    "    return data, population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, population = get_data_and_population(all_counties, statvars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize the data if applicable and compute distance\n",
    "Here we will first normalize the data if per_capita is True\n",
    "We then for each statistical variable, compute distance between query county and every other county. The smaller the distance is, the more similar two counties are based on this statistical variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(data, population, per_capita):\n",
    "    data = copy.deepcopy(data)\n",
    "    # if cannot normalize all values for a place, drop this place\n",
    "    assert len(data) == len(per_capita)\n",
    "    for i in range(len(per_capita)):\n",
    "        if per_capita[i]:\n",
    "            current_data = data[i]\n",
    "            for k in current_data.keys():\n",
    "                if current_data[k] is not None and population[k] is not None:\n",
    "                    current_data_place = current_data[k]['data']\n",
    "                    population_place = population[k]['data']\n",
    "                    data[i][k]['data'] = normalize_single(current_data_place, population_place)\n",
    "    return data\n",
    "\n",
    "def normalize_single(data_dict, population_dict):\n",
    "    new_data_dict = {}\n",
    "    population_years = sorted(list(population_dict.keys()))\n",
    "    for k in data_dict.keys():\n",
    "        if k[:4] in population_years:\n",
    "            new_data_dict[k] = data_dict[k] / population_dict[k[:4]]\n",
    "        elif int(k[:4]) > int(population_years[-1]):\n",
    "            new_data_dict[k] = data_dict[k] / population_dict[population_years[-1]]\n",
    "    return new_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distances(query_dcid, data, statvars, time_series, time_series_similarity_types):\n",
    "    distance_lists = []\n",
    "    for i in range(len(data)):\n",
    "        print('processing {0} data'.format(statvars[i]))\n",
    "        distance_lists.append(get_distance_all(data[i], query_dcid, time_series[i], time_series_similarity_types[i]))\n",
    "    return distance_lists\n",
    "\n",
    "def get_distance_all(data_dict, query, time_series, time_series_similarity_type):\n",
    "    id_list = []\n",
    "    distance_list = []\n",
    "    if 'data' not in data_dict[query]:\n",
    "        return {}\n",
    "    query_dict = data_dict[query]['data']\n",
    "    for k in data_dict.keys():\n",
    "        id_list.append(k)\n",
    "        # if 'data' in data_dict[k].keys():  # Before API change\n",
    "        if data_dict[k] is not None and 'data' in data_dict[k].keys():\n",
    "            distance_list.append(get_distance_pair(query_dict, data_dict[k]['data'], time_series, time_series_similarity_type))\n",
    "        else:\n",
    "            distance_list.append(get_distance_pair(query_dict, {}, time_series, time_series_similarity_type))\n",
    "\n",
    "    id_list, distance_list = (list(t) for t in zip(*sorted(zip(id_list, distance_list))))\n",
    "    return distance_list\n",
    "\n",
    "def get_distance_pair(dict_a, dict_b, time_series, time_series_similarity_type):\n",
    "    common_dates = get_common_keys(dict_a, dict_b)\n",
    "    if len(common_dates) == 0:\n",
    "        return float('inf')\n",
    "    common_series_a = [dict_a[date] for date in common_dates]\n",
    "    common_series_b = [dict_b[date] for date in common_dates]\n",
    "    if time_series:\n",
    "        if time_series_similarity_type == 'pearson':\n",
    "            if len(common_series_a) < 2:\n",
    "                return float('inf')  # due to insufficient number of data points\n",
    "            else:\n",
    "                r, p = pearsonr(common_series_a, common_series_b)  # need to convert correlation to some distance measure\n",
    "                return 1 - r\n",
    "        elif time_series_similarity_type == 'mse':\n",
    "            return np.square(np.subtract(common_series_a, common_series_b)).mean()\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "    else:\n",
    "        return abs(common_series_a[-1] - common_series_b[-1])\n",
    "\n",
    "def get_common_keys(dict_a, dict_b):\n",
    "    return sorted(list(set(dict_a.keys()).intersection(set(dict_b.keys()))))\n",
    "\n",
    "def convert_dict_to_list(d):\n",
    "    sorted_dict = sorted(d.items())  # sorted by key, return a list of tuples\n",
    "    x, y = zip(*sorted_dict)  # unpack a list of pairs into two tuples\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_data = normalize_data(data, population, per_capita)\n",
    "distance_lists = compute_distances(query_dcid, data, statvars, time_series, time_series_similarity_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving similar counties\n",
    "First we will retrieve counties that are similar to Santa Clara.\n",
    "This is achieved by setting similar to True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_all_remove_inf(id_list, distance_lists, similar):\n",
    "    distances = np.array(distance_lists)\n",
    "    inf_indices = list(set(np.where(distances == float('inf'))[1]))\n",
    "    new_id_list = np.delete(id_list, inf_indices)\n",
    "    new_distances = np.delete(distances, inf_indices, axis=1)\n",
    "    assert len(new_id_list) == new_distances.shape[1]\n",
    "    ranks = np.zeros((new_distances.shape[1]))\n",
    "    for i in range(new_distances.shape[0]):\n",
    "        ranks = ranks + rankdata(new_distances[i, :], method='min')\n",
    "    if not similar:\n",
    "        topK = np.argsort(-ranks)\n",
    "    else:\n",
    "        topK = np.argsort(ranks)\n",
    "    return new_id_list[topK]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar = True # True for retrieving least similar entities\n",
    "all_dcid_ranked = rank_all_remove_inf(id_list, distance_lists, similar)\n",
    "# delete query dcid and add back to the front approriately due to tie conditions\n",
    "all_dcid_ranked = all_dcid_ranked[all_dcid_ranked != query_dcid]\n",
    "all_dcid_ranked = np.insert(all_dcid_ranked, 0, query_dcid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize our results\n",
    "For time series data, we show the retrieval counties by plotting them pairwise per graph.\n",
    "For snapshot data, we show the retrieval counties in a table\n",
    "Let's Define some plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_plot(x_list, y_list, x_label, y_label, legends):\n",
    "    assert len(x_list) == len(y_list)\n",
    "    assert len(x_list) == len(legends)\n",
    "    for i in range(len(x_list)):\n",
    "        x = x_list[i]\n",
    "        y = y_list[i]\n",
    "        x = matplotlib.dates.datestr2num(x)\n",
    "        plt.plot_date(x, y, label=legends[i])\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show()\n",
    "def visualize_all(normalized_data, query_dcid, all_dcid_ranked, all_counties, statvar_display_names, k, time_series, all_states):\n",
    "    snapshot_indices = []\n",
    "    for i in range(len(time_series)):\n",
    "        if not time_series[i]:\n",
    "            snapshot_indices.append(i)\n",
    "    df = visualize_snapshots(normalized_data, query_dcid, all_dcid_ranked, all_counties, statvar_display_names, snapshot_indices, all_states)\n",
    "    for i in range(len(time_series)):\n",
    "        if time_series[i]:\n",
    "            print('===================================Plotting {0} time series==================================='.format(statvar_display_names[i]))\n",
    "            visualize_time_series_single(normalized_data[i], query_dcid, all_dcid_ranked, all_counties, statvar_display_names[i], k)\n",
    "    return df\n",
    "\n",
    "\n",
    "def visualize_time_series_single(current_data, query_dcid, all_dcid_ranked, all_counties, statvar_display_name, k):\n",
    "    query_x, query_y = convert_dict_to_list(current_data[query_dcid]['data'])\n",
    "    for j in range(k):\n",
    "        current_x, current_y = convert_dict_to_list(current_data[all_dcid_ranked[j + 1]]['data'])\n",
    "        multiple_plot([query_x, current_x], [query_y, current_y], 'time', statvar_display_name, [all_counties[query_dcid][0], all_counties[all_dcid_ranked[j + 1]][0]])\n",
    "\n",
    "\n",
    "def visualize_snapshots(normalized_data, query_dcid, all_dcid_ranked, all_counties, statvar_display_names, snapshot_indices, all_states):\n",
    "    results = []\n",
    "    query_series_list = []\n",
    "    for index in snapshot_indices:\n",
    "        query_series_list.append(normalized_data[index][query_dcid]['data'])\n",
    "    for i in range(len(all_dcid_ranked)):\n",
    "        dcid = all_dcid_ranked[i]\n",
    "        current = [dcid, all_counties[dcid][0], all_states[dcid[:8]][0]]\n",
    "        for j in range(len(snapshot_indices)):\n",
    "            current_series = normalized_data[snapshot_indices[j]][dcid]['data']\n",
    "            date = get_common_keys(query_series_list[j], current_series)[-1]\n",
    "            value = current_series[date]\n",
    "            current.extend([value, date])\n",
    "        results.append(current)\n",
    "    columns = ['dcid', 'name', 'state']\n",
    "    for i in range(len(snapshot_indices)):\n",
    "        columns.extend([statvar_display_names[snapshot_indices[i]], statvar_display_names[snapshot_indices[i]] + '_date'])\n",
    "    df = pd.DataFrame(results, columns=columns)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = visualize_all(normalized_data, query_dcid, all_dcid_ranked, all_counties, statvar_display_names, K, time_series, all_states)\n",
    "df.head(K + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's retrieve dissimilar counties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar = False # True for retrieving least similar entities\n",
    "all_dcid_ranked = rank_all_remove_inf(id_list, distance_lists, similar)\n",
    "# delete query dcid and add back to the front approriately due to tie conditions\n",
    "all_dcid_ranked = all_dcid_ranked[all_dcid_ranked != query_dcid]\n",
    "all_dcid_ranked = np.insert(all_dcid_ranked, 0, query_dcid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = visualize_all(normalized_data, query_dcid, all_dcid_ranked, all_counties, statvar_display_names, K, time_series, all_states)\n",
    "df.head(K + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encapsulate the above functions to one single function\n",
    "After we understand the functionality of each function, let's define one function that gets the data, normalize it, compute distance and display results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_compute_visualize(query_dcid, restrict_same_state, statvars, statvar_display_names, per_capita, time_series, time_series_similarity_types, similar, k):\n",
    "    if restrict_same_state:\n",
    "        place_domain = dc.get_property_values([query_dcid], 'containedInPlace')[query_dcid][0]\n",
    "    else:\n",
    "        place_domain = 'country/USA'\n",
    "    all_states = dc.get_places_in(['country/USA'], \"State\")['country/USA']\n",
    "    all_states = dc.get_property_values(all_states, \"name\")\n",
    "    all_counties = dc.get_places_in([place_domain], \"County\")[place_domain]\n",
    "    all_counties = dc.get_property_values(all_counties, \"name\")\n",
    "    id_list = sorted(list(all_counties.keys()))\n",
    "    data, population = get_data_and_population(all_counties, statvars)\n",
    "    normalized_data = normalize_data(data, population, per_capita)\n",
    "    distance_lists = compute_distances(query_dcid, data, statvars, time_series, time_series_similarity_types)\n",
    "    all_dcid_ranked = rank_all_remove_inf(id_list, distance_lists, similar)\n",
    "    all_dcid_ranked = all_dcid_ranked[all_dcid_ranked != query_dcid]\n",
    "    all_dcid_ranked = np.insert(all_dcid_ranked, 0, query_dcid)\n",
    "    df = visualize_all(normalized_data, query_dcid, all_dcid_ranked, all_counties, statvar_display_names, k, time_series, all_states)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single statistical variable time series case\n",
    "We again look at Santa Clara county but this time focus on median income in time series. We choose Pearson correlation to measure similarity and once again, restrict ourselves to California state only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_dcid = 'geoId/06085' # Santa Clara county\n",
    "restrict_same_state = True\n",
    "K = 10\n",
    "statvars = ['Median_Income_Person']\n",
    "per_capita = [False]\n",
    "time_series = [True]\n",
    "time_series_similarity_types = ['pearson']\n",
    "statvar_display_names = ['Median Income']\n",
    "similar = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe indeed the median income time series plots show similar trend on median income even though their difference is consistently large in some cases. This is expected since we used Pearson correlation coefficient, which unlike MSE, is looking at trend rather than absolute value differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = retrieve_compute_visualize(query_dcid, restrict_same_state, statvars, statvar_display_names, per_capita, time_series, time_series_similarity_types, similar, K)\n",
    "df.head(K + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change it to mse and rerun everything\n",
    "Now every corresponding observations are much more closer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_similarity_types = ['mse']\n",
    "df = retrieve_compute_visualize(query_dcid, restrict_same_state, statvars, statvar_display_names, per_capita, time_series, time_series_similarity_types, similar, K)\n",
    "df.head(K + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can even look at both metrics at the same time\n",
    "In this case, for each metric, the algorithm considers it indepedently and assign ranks to every places based on the comuputed similarity. The rank is then aggregated to produce the final retrieval results.\n",
    "\n",
    "You will see two identical sets of figures. This is due to the fact that our algorithm actually treats the two metrics as two different statistical variables, and it will plot for the retrieval results for each statistical variables indepdently. This is helpful when we are looking at multiple statistical variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statvars = ['Median_Income_Person', 'Median_Income_Person']\n",
    "per_capita = [False, False]\n",
    "time_series = [True, True]\n",
    "time_series_similarity_types = ['mse', 'pearson']\n",
    "statvar_display_names = ['Median Income Pearson', 'Median Income MSE']\n",
    "df = retrieve_compute_visualize(query_dcid, restrict_same_state, statvars, statvar_display_names, per_capita, time_series, time_series_similarity_types, similar, K)\n",
    "df.head(K + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we can look at multiple statistical variables at the same time!\n",
    "We look at three statistical variables: unemployment rate, median income, labour force participation rate. Since Data Commons does not have per capita statistics for labour force, we set per capita to True for that variable. We look at the first two statistical variables with time series based on Pearson correlation and labour force participation rate as snapshot. The plots for unemployment rate and median income show very similar trend between Santa Clara county and retrieved places. The labour force participation rate is very close between query county and retrieved counties as well.\n",
    "This time, we will look at all counties in US, not just California. So it may take a while to get the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statvars = ['UnemploymentRate_Person', 'Median_Income_Person', 'Count_Person_InLaborForce']\n",
    "per_capita = [False, False, True]\n",
    "time_series = [True, True, False]\n",
    "restrict_same_state = False  # look at all counties in US\n",
    "statvar_display_names = ['Unemployment Rate', 'Median Income', 'Labor Force Per Capita']\n",
    "time_series_similarity_types = ['pearson', 'pearson', '']  # omit the last element since we are looking at snapshot case for labour force\n",
    "df = retrieve_compute_visualize(query_dcid, restrict_same_state, statvars, statvar_display_names, per_capita, time_series, time_series_similarity_types, similar, K)\n",
    "df.head(K + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choropleth Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we just computed similarity for all counties, we will display a choropleth (heatmap) allowing us to visualize a geographical distribution of counties that are similar to Santa Clara based on the statistical variables and settings we just described. In the below heatmap, the darker the color is, the similar the county is with Santa Clara. This may take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap_visualization(df, display_topK, k):\n",
    "    filename = 'us_counties.json'\n",
    "    with urlopen('https://raw.githubusercontent.com/plotly/datasets/master/geojson-counties-fips.json') as response:\n",
    "        counties_geo = json.load(response)\n",
    "    df_choro = copy.deepcopy(df)\n",
    "    df_choro['dcid'] = df_choro['dcid'].apply(lambda x: str(x).replace('geoId/', ''))\n",
    "    if display_topK:\n",
    "        df_choro = df_choro[:k + 1]\n",
    "    fig = px.choropleth(df_choro, geojson=counties_geo, locations='dcid', color=df_choro.index,\n",
    "                        color_continuous_scale=\"Viridis\",\n",
    "                        range_color=(0, len(df_choro) - 1),\n",
    "                        scope=\"usa\",\n",
    "                        labels={'index': 'rank'}, hover_data={'name'}\n",
    "                        )\n",
    "    fig.update_layout(margin={\"r\": 0, \"t\": 0, \"l\": 0, \"b\": 0})\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_topK = False\n",
    "heatmap_visualization(df, display_topK, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's Next?\n",
    "You can explore more statistical variable combinations with different settings (snapshot/time series, per capita or different similarity metrics or all of them)! Also don't forget you can change your query county to somewhere else. We provide a few suggestions below just to get you started! Good luck with exploring!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_dcid = 'geoId/36103' # Suffolk county\n",
    "restrict_same_state = False\n",
    "statvars = ['Amount_EconomicActivity_GrossDomesticProduction_RealValue', 'Count_Establishment', 'WagesAnnual_Establishment']\n",
    "statvar_display_names = ['GDP', 'Number of Establishments', 'Annual Wages of Establishments']\n",
    "per_capita = [True, True, True]\n",
    "time_series = [True, True, False]\n",
    "time_series_similarity_types = ['pearson', 'pearson', '']\n",
    "similar = True\n",
    "K = 10\n",
    "df = retrieve_compute_visualize(query_dcid, restrict_same_state, statvars, statvar_display_names, per_capita, time_series, time_series_similarity_types, similar, K)\n",
    "df.head(K + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_dcid = 'geoId/15001' # Hawaii county\n",
    "restrict_same_state = False\n",
    "statvars = ['CumulativeCount_MedicalConditionIncident_COVID_19_ConfirmedOrProbableCase', 'CumulativeCount_MedicalConditionIncident_COVID_19_PatientDeceased']\n",
    "statvar_display_names = ['Confirmed or Probable Cases', 'Patients Deceased']\n",
    "per_capita = [False, False]\n",
    "time_series = [False, False]\n",
    "time_series_similarity_types = ['', '']\n",
    "similar = True\n",
    "K = 10\n",
    "df = retrieve_compute_visualize(query_dcid, restrict_same_state, statvars, statvar_display_names, per_capita, time_series, time_series_similarity_types, similar, K)\n",
    "df.head(K + 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
