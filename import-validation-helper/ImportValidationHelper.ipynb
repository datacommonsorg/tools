{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ImportValidationHelper.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "OtqIpPaUiMZF"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tjann/tools/blob/importhelper/ImportValidationHelper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sTKUefKWTfr",
        "colab_type": "text"
      },
      "source": [
        "# Import Validation Helper\n",
        "This Colab notebook introduces a few tools to check your template MCF, StatVars, and CSV. \n",
        "\n",
        "A summary of features is as follows.\n",
        "\n",
        "*   MCF format checking (no improperly defined nodes).\n",
        "*   StatVar reference checking (makes sure that all references either exist locally or in the knowledge graph).\n",
        "*   TMCF and CSV column valididation.\n",
        "*   Description spell checking.\n",
        "*   ASCII encoding checking.\n",
        "\n",
        "### Usage summary:\n",
        "1.   Runtime -> Run All\n",
        "2.   Authenticate with BigQuery in second cell\n",
        "3.   Scroll to bottom, select three files to validate from your local computer.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CGTarNhjPuB",
        "colab_type": "text"
      },
      "source": [
        "# 1) At the top of the page, go to \"Runtime -> Run All\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHlcR9km48T7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "!pip install --upgrade -q pyspellchecker\n",
        "!pip install --upgrade -q pygsheets\n",
        "\n",
        "from spellchecker import SpellChecker\n",
        "import subprocess\n",
        "\n",
        "from google.colab import auth\n",
        "from google.cloud import bigquery\n",
        "import gspread\n",
        "from oauth2client.client import GoogleCredentials\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6f4ZjU27iEM9",
        "colab_type": "text"
      },
      "source": [
        "# 2) Authenticate BQ here.\n",
        "BigQuery is used to check your used references against the KG."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZx5kuFd_76D",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title Do you have BigQuery Access? (Internal Googler)\n",
        "bq_access = True\n",
        "\n",
        "if bq_access:\n",
        "  auth.authenticate_user()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtqIpPaUiMZF",
        "colab_type": "text"
      },
      "source": [
        "## Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfqqK8zg-384",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Setup BQ client\n",
        "client = None\n",
        "if bq_access:\n",
        "  project_id = \"google.com:datcom-store-dev\"\n",
        "  client = bigquery.Client(project=project_id)\n",
        "\n",
        "# Setup logging\n",
        "# gc = gspread.authorize(GoogleCredentials.get_application_default())\n",
        "\n",
        "# Enum definition\n",
        "from enum import Enum\n",
        "class PrecheckError(Enum):\n",
        "  CRITICAL = \"Critical\"\n",
        "  WARN = \"Warn\"\n",
        "\n",
        "# Helpers\n",
        "cache = {}\n",
        "\n",
        "def validateNodeStructure(mcf_contents):\n",
        "  # See if node has been processed\n",
        "  hash_of_contents = \"validateNodeStructure_\" + str(hash(mcf_contents))\n",
        "  if hash_of_contents in cache:\n",
        "    return cache[hash_of_contents]\n",
        "\n",
        "  # Nodes in an MCF file are separated by a blank line \n",
        "  mcf_nodes_text = mcf_contents.split(\"\\n\\n\")\n",
        "\n",
        "  # Lines in an MCF file are separated as property: constraint\n",
        "  mcf_line = re.compile(r\"^(\\w+): (.*)$\")\n",
        "\n",
        "  mcf_nodes = []\n",
        "  errors = []\n",
        "\n",
        "  for node in mcf_nodes_text:\n",
        "    current_mcf_node = {}\n",
        "\n",
        "    for line in node.split('\\n'):\n",
        "      # Ignore blank lines if multiple spaces between lines\n",
        "      if len(line) == 0:\n",
        "        continue\n",
        "\n",
        "      parsed_line = mcf_line.match(line)\n",
        "\n",
        "      if parsed_line is None:\n",
        "        errors.append((PrecheckError.CRITICAL, \"MalformedLine\", f\"Malformed MCF Line '{line}'\"))\n",
        "      else:\n",
        "        # Property = Constraint\n",
        "        current_mcf_node[parsed_line.group(1)] = parsed_line.group(2)\n",
        "        \n",
        "    if len(current_mcf_node) > 0:\n",
        "      mcf_nodes.append(current_mcf_node)\n",
        "\n",
        "  # Add to cache\n",
        "  cache[hash_of_contents] = (mcf_nodes, errors)\n",
        "\n",
        "  return mcf_nodes, errors\n",
        "  \n",
        "def get_nodes_with_property(mcf_contents, prop, constraint):\n",
        "  mcf_nodes, errors = validateNodeStructure(mcf_contents)\n",
        "\n",
        "  matching_nodes = []\n",
        "  for node in mcf_nodes:\n",
        "    if prop in node and node[prop] == constraint:\n",
        "      matching_nodes.append(node)\n",
        "\n",
        "  return matching_nodes\n",
        "\n",
        "def remove_prefix(s):\n",
        "  \"\"\"Removes prefixes 'dcs:', 'dcid:' and 'schema:' to ease node comparison.\"\"\"\n",
        "  s = s.strip()\n",
        "  if s.startswith('dcs:'):\n",
        "    return s[4:]\n",
        "  if s.startswith('dcid:'):\n",
        "    return s[5:]\n",
        "  if s.startswith('schema:'):\n",
        "    return s[7:]\n",
        "  return s\n",
        "\n",
        "def cmp_nodes(n1, n2):\n",
        "  \"\"\"Compares two nodes, ignoring prefixes such as in remove_prefix()\"\"\"\n",
        "  return remove_prefix(n1) == remove_prefix(n2)\n",
        "\n",
        "def get_newly_defined_nodes(mcf_contents, typeOf = \"\"):\n",
        "  mcf_nodes, errors = validateNodeStructure(mcf_contents)\n",
        "\n",
        "  new_nodes = []\n",
        "  for node in mcf_nodes:\n",
        "    if \"Node\" in node and \"typeOf\" in node and \\\n",
        "        (typeOf == \"\" or typeOf == remove_prefix(node['typeOf'])):\n",
        "      new_nodes.append(node['Node'].replace(\"dcs:\",\"\").replace(\"dcid:\",\"\"))\n",
        "\n",
        "  return new_nodes\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwyIS2U_iQUc",
        "colab_type": "text"
      },
      "source": [
        "## Definition of Tests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08YdJ9R14-Pu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TriplesChecks():\n",
        "  \"\"\"Defines the various tests that run on the combined contents of TMCF,\n",
        "  uploaded csv, and statistical variable files. \n",
        "  \n",
        "  To add a test: Make a new method with the following args.\n",
        "    Args:\n",
        "      df -> Dataframe of uploaded CSV\n",
        "      tmcf_contents -> String of TMCF text content\n",
        "      stat_vars -> String of Statistical Variables file\n",
        "    Yields:\n",
        "      Yields tuple of the precheck error level enum, error name, and an error message\n",
        "  \"\"\"\n",
        "\n",
        "  def ensure_ascii(_, tmcf_contents, stat_vars_content):\n",
        "    \"\"\"Checks to ensure that files contents are solely ascii characters.\"\"\"\n",
        "    ascii_character_match = re.compile(r\"^[\\x00-\\x7F]+$\")\n",
        "\n",
        "    for file_name, contents in \\\n",
        "        [(\"TMCF\", tmcf_contents), (\"Statistical Variables\", stat_vars_content)]:\n",
        "\n",
        "      if ascii_character_match.match(contents) == None:\n",
        "        yield (PrecheckError.CRITICAL, \"NonAsciiInFile\",\n",
        "          f\"{file_name} file contains non-ascii characters.\")\n",
        "\n",
        "  def tmcf_csv_column_checks(df, tmcf_contents, stat_vars_content):\n",
        "    \"\"\"Handles column inconsistencies between tmcf and csv.\"\"\"\n",
        "    column_matches = re.compile(r\"C:\\w+->(\\w+)\")\n",
        "    tmcf_columns = column_matches.findall(tmcf_contents)\n",
        "    csv_columns = df.columns\n",
        "    for column in tmcf_columns:\n",
        "      if column not in csv_columns:\n",
        "        yield (PrecheckError.CRITICAL, \"ColInTMCFMissingFromCSV\",\n",
        "          f\"Referenced column {column} in TMCF not found in CSV.\")\n",
        "    for column in csv_columns:\n",
        "      if column not in tmcf_columns:\n",
        "        yield (PrecheckError.WARN, \"UnusedColumnPresent\",\n",
        "          f\"Unused column {column} present in CSV.\")\n",
        "        \n",
        "  def ensure_mcf_not_malformed(_, tmcf_contents, stat_vars_content):\n",
        "    \"\"\"Ensures lines of MCF files are property defined.\n",
        "    Passes: Node: E:WorldBank->E0\n",
        "    Fails: Node E:WorldBank->E0 \n",
        "    \"\"\"\n",
        "    # Grab error field of tuple\n",
        "    for error in validateNodeStructure(tmcf_contents)[1]:\n",
        "      yield error\n",
        "\n",
        "    for error in validateNodeStructure(stat_vars_content)[1]:\n",
        "      yield error\n",
        "\n",
        "  def ensure_nodes_properly_referenced(_, tmcf_contents, stat_vars_content):\n",
        "    \"\"\"Ensures that constraint field of mcf files are references or constants.\"\"\"\n",
        "    tmcf_nodes, _ = validateNodeStructure(tmcf_contents)\n",
        "    stat_var_nodes, _ = validateNodeStructure(stat_vars_content)\n",
        "\n",
        "    # Ensure that each property is a string, integer, boolean, tmcf reference, or schema reference \n",
        "    tmcf_match = re.compile(r\"^(\\\"[^\\\"]+\\\")|(E:\\w+->E\\d+)|(C:\\w+->\\w+)|(\\d+)|(True)|(False)|(((dcs)|(dcid)|(schema)):\\w+)$\")\n",
        "\n",
        "    # Ensure that each property is a string, integer, boolean, tmcf reference, schema reference, or quantity range\n",
        "    stvr_match = re.compile(r\"^(\\\"[^\\\"]+\\\")|(\\d+)|(True)|(False)|((((dcs)|(dcid)|(schema)):[A-Za-z0-9_\\-\\/]+,? ?)+)|(\\[\\S+ ((\\d+)|(\\d+ \\d+)|(\\d+ \\+)|(\\- \\d+))\\])$\")\n",
        "    tmcf_node_match = re.compile(\"^E:\\S+->E\\d+$\")\n",
        "    stvr_node_match = re.compile(\"^dcid:\\S+$\")\n",
        "\n",
        "    for node_list, node_prop_regex, property_regex in \\\n",
        "        [(tmcf_nodes, tmcf_node_match, tmcf_match),\n",
        "         (stat_var_nodes, stvr_node_match, stvr_match)]:\n",
        "      for node in node_list:\n",
        "        for prop, constraint in node.items():\n",
        "          if prop == \"Node\":\n",
        "            if node_prop_regex.match(constraint) == None:\n",
        "              yield (PrecheckError.CRITICAL, \"MalformedNode\",\n",
        "                     f\"Malformed Node Property '{prop}: {constraint}'\")\n",
        "          \n",
        "          # Validate properties of TMCF\n",
        "          elif prop[0].islower():\n",
        "            if property_regex.match(constraint) == None:\n",
        "              yield (PrecheckError.WARN, \"MisformedReference\",\n",
        "                     f\"Misformed Reference: '{prop}: {constraint}'\")\n",
        "\n",
        "          # All properties besides Node should be lower case\n",
        "          else:\n",
        "            yield (PrecheckError.WARN, \"LowerProperties\",\n",
        "                f\"All MCF Properties besides Node should be lowercase. Triggered for '{prop}'.\")\n",
        "    \n",
        "  def spell_check_descriptions(_, tmcf_contents, stat_vars_content):\n",
        "    \"\"\"Provides spell checking on all description fields.\"\"\"\n",
        "    description_field_parser = re.compile(\"description: \\\"([^\\\"]*)\\\"\")\n",
        "    spell = SpellChecker()\n",
        "    sets_to_check = [(\"TMCF\", tmcf_contents), \n",
        "                      (\"Statistical Variables\", stat_vars_content)]\n",
        "\n",
        "    for set_name, text in sets_to_check:\n",
        "      potential_mispellings = set()\n",
        "      for description in description_field_parser.findall(text):\n",
        "        potential_mispellings = potential_mispellings.union(\n",
        "            spell.unknown(spell.split_words(description))\n",
        "        )\n",
        "\n",
        "      if len(potential_mispellings) != 0:\n",
        "        yield (PrecheckError.WARN, \"Misspelling\",\n",
        "            f\"Potential Misspelling(s) in {set_name}: {list(potential_mispellings)})\")\n",
        "\n",
        "  def ensure_all_references_exist(df, tmcf_contents, stat_vars_content):\n",
        "    if not bq_access:\n",
        "      return\n",
        "      \n",
        "    # Get locally defined instances.\n",
        "    new_references = get_newly_defined_nodes(stat_vars_content)\n",
        "\n",
        "    # Get all references instances in stat vars\n",
        "    ref_finder = re.compile(r\"(?:(?:dcs)|(?:dcid)):(\\S+)\")\n",
        "    references = list(set(ref_finder.findall(stat_vars_content)))\n",
        "\n",
        "    # Get all stat vars that are not locally defined\n",
        "    global_references = []\n",
        "    for ref in references:\n",
        "      if len(ref) != 0 and ref not in new_references:\n",
        "        global_references.append(ref)\n",
        "\n",
        "    # Query database \n",
        "    instance_query = \"\"\"\n",
        "    SELECT distinct id\n",
        "    FROM `google.com:datcom-store-dev.dc_v3_clustered.Instance` \n",
        "    WHERE id IN ({str})\n",
        "    \"\"\"\n",
        "    obj_instances = client.query(instance_query.replace(\"{str}\",\n",
        "      str(global_references).lstrip(\"[\").rstrip(\"]\"))).to_dataframe()['id'].values\n",
        "\n",
        "    missing_references = []\n",
        "    for ref in global_references:\n",
        "      if ref not in obj_instances:\n",
        "        missing_references.append(ref)\n",
        "\n",
        "    if len(missing_references) != 0:\n",
        "      yield (PrecheckError.WARN, \"UndefinedReference\",\n",
        "                f\"Potential Undefined References: {missing_references}\")\n",
        "    \n",
        "  def ensure_all_statvars_defined(df, tmcf_contents, stat_vars_content):\n",
        "    direct_ref = re.compile(r'variableMeasured:\\s(\\w+)$')\n",
        "    indirect_ref = re.compile(r'variableMeasured:\\sC:\\w+->(\\w+)')\n",
        "    defined_nodes = get_newly_defined_nodes(stat_vars_content)\n",
        "    for ref in direct_ref.findall(tmcf_contents):\n",
        "      if not any([cmp_nodes(ref, n) for n in defined_nodes]):\n",
        "        yield (PrecheckError.CRITICAL, \"TMCFNodeRefNotInMCF\",\n",
        "              f\"Node '{ref}' referenced in TMCF, undefined in MCF.\")\n",
        "    \n",
        "    for col_ref in indirect_ref.findall(tmcf_contents):\n",
        "      if col_ref not in df.columns:\n",
        "        yield (PrecheckError.CRITICAL, \"ColInTMCFNotInCSV\",\n",
        "              f\"Column '{col_ref}' referenced in TMCF, not in CSV.\")\n",
        "      else:\n",
        "        for ref in df[col_ref].unique():\n",
        "          if not any([cmp_nodes(ref, n) for n in defined_nodes]):\n",
        "            yield (PrecheckError.CRITICAL, \"ReferencedFieldNotInMcf\",\n",
        "                  f\"Node '{ref}' referenced in TMCF through '{col_ref}' column in CSV, undefined in MCF.\")\n",
        "  \n",
        "  def ensure_dcid_not_too_long(_, __, stat_vars_content):\n",
        "    for line in stat_vars_content.split(\"\\n\"):\n",
        "      if 'Node:' in line and len(line) - len('Node: ') > 256:\n",
        "        yield (PrecheckError.CRITICAL, \"MalformedNode\",\n",
        "              f\"The following node is too long: '{line.strip()}'\\nMax dcid length is 256.\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbJptJFUBnKv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8G8pWgrhAVen",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7Tbwl3CrKN-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from optparse import OptionParser\n",
        "import inspect\n",
        "\n",
        "def validate_prechecks(df, tmcf_contents, stat_vars_content, demo=False):\n",
        "  \"\"\"Runs validation checks on provided triples.\n",
        "\n",
        "  Args:\n",
        "      df -> Dataframe of uploaded CSV\n",
        "      tmcf_contents -> String of TMCF text content\n",
        "      stat_vars_content -> String of Statistical Variables file\n",
        "  \"\"\"\n",
        "  # Log usage to find common errors\n",
        "  # process = subprocess.Popen(\"gcloud config get-value account\", shell=True, stdout=subprocess.PIPE)\n",
        "  # username = process.stdout.read().decode(\"utf-8\")\n",
        "  # gc = gspread.authorize(GoogleCredentials.get_application_default())\n",
        "  # workbook = gc.open_by_url('https://docs.google.com/spreadsheets/d/1l4YqvkhzRBKtab5lVCuoR0guGf2qIARK-A995DFZ6Nw/edit?usp=sharing')\n",
        "  # sheet = workbook.worksheet('Usage')\n",
        "  # if demo:\n",
        "      # sheet.append_row([username, \"RanDemo\"])\n",
        "\n",
        "  for function_name, function in inspect.getmembers(TriplesChecks, predicate=inspect.isfunction):\n",
        "    errors = list(function(df, tmcf_contents, stat_vars_content))\n",
        "    if len(errors) != 0:\n",
        "      print(f\"Error In Test {function_name}\")\n",
        "      for error in errors: \n",
        "        # if not demo:\n",
        "          # sheet.append_row([username, str(error[0].value), error[1], error[2]])\n",
        "        print(f\"{error[0].value} - {error[2]}\")\n",
        "      print(\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zqZfVVAo9bQ",
        "colab_type": "text"
      },
      "source": [
        "# Sample Upload Demonstrating Common Errors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unseBz2v7ziU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Sample Input\n",
        "stat_vars_content = \\\n",
        "\"\"\"\n",
        "Node: dcid:Tourism\n",
        "name: “Tourism“\n",
        "typeOf: dcid:TravelPurposeEnum\n",
        "description: \"Ptential mispeling in my description.\" \n",
        "\n",
        "Node: dcid:ThisIsAnExtremelyLongStatVarName__Count_MortalityEvent_From75To79Years_MalignantImmunoproliferativeDiseasesAndCertainOtherB-CellLymphomas_MultipleMyelomaAndMalignantPlasmaCellNeoplasms_OtherAndUnspecifiedMalignantNeoplasmsOfLymphoid_HematopoieticAndRelatedTissue_Female_AsFractionOf_Count_Person\n",
        "name: “Tourism“\n",
        "typeOf: dcid:TravelPurposeEnum\n",
        "description: \"Ptential mispeling in my description.\" \n",
        "\"\"\"\n",
        "\n",
        "tmcf_contents = \\\n",
        "\"\"\"\n",
        "Node E:WorldBank->E0\n",
        "typeOf: dcs:StatVarObservation\n",
        "variableMeasured: C:WorldBank->StatisticalVariable\n",
        "observationDate: C:WorldBank->Year\n",
        "observationPeriod: \"P1Y\"\n",
        "observationAbout: E:WorldBank->E1\n",
        "value: C:WorldBank->Value\n",
        "\n",
        "Node: E:WorldBank->E1\n",
        "typeOf: dcs:Country\n",
        "countryAlpha3Code: C:WorldBank->IsoCode\n",
        "BadProperty: someFieldThatShouldBeAReferenceButIsInterpretedAsAString\n",
        "\"\"\"\n",
        "\n",
        "df = pd.DataFrame.from_dict({\"Value\": [4], \"IsoCode\": [\"USA\"], \"Year\":[2018], \"Foo\": ['bar']})\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9s8-wZNrXKE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validate_prechecks(df, tmcf_contents, stat_vars_content, demo=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TYYTYGJoJEZ",
        "colab_type": "text"
      },
      "source": [
        "# Real Validation Code\n",
        "\n",
        "Upload three files.\n",
        "\n",
        "- StatisticalVariable -> Needs to end in .mcf\n",
        "- Template MCF -> Needs to end in .tmcf\n",
        "- CSV File -> Needs to end in .csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMTKha2y8PQ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "from io import StringIO\n",
        "\n",
        "LARGE_FILE_FLAG = False # Set this to true for large files\n",
        "selected_files = files.upload()\n",
        "\n",
        "# Parse out files\n",
        "df, tmcf_text, stat_var_text = None, None, None\n",
        "\n",
        "for file, contents in selected_files.items():\n",
        "  if \".csv\" in file:\n",
        "    if not LARGE_FILE_FLAG:\n",
        "      df = pd.read_csv(StringIO(contents.decode()))\n",
        "    else:\n",
        "      df = pd.read_csv(StringIO(contents.decode()), nrows=100)\n",
        "  elif \".tmcf\" in file:\n",
        "    tmcf_text = contents.decode()\n",
        "  elif \".mcf\" in file:\n",
        "    stat_var_text = contents.decode()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4_63BXZsxtx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validate_prechecks(df, tmcf_text, stat_var_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfEfIQMNtiIK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}